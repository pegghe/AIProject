{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb3115f",
   "metadata": {},
   "source": [
    "Importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7eaafba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3052625e",
   "metadata": {},
   "source": [
    "Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ad176413",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_foldername = \"~/OneDrive - Università degli Studi di Milano-Bicocca/Magistrale/AI/cleaned_datasets_students\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "38c39b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interactions = pd.read_csv(f\"{dataset_foldername}/train_interactions.csv\")\n",
    "games = pd.read_csv(f\"{dataset_foldername}/games.csv\")\n",
    "test_interactions_in = pd.read_csv(f\"{dataset_foldername}/test_interactions_in.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d361aa",
   "metadata": {},
   "source": [
    "STUDY OF THE DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cc4b19",
   "metadata": {},
   "source": [
    "Brief overview of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1ee106f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>playtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>448211.000000</td>\n",
       "      <td>448211.000000</td>\n",
       "      <td>448211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25832.526716</td>\n",
       "      <td>2992.618144</td>\n",
       "      <td>1539.262254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17466.683483</td>\n",
       "      <td>2879.200191</td>\n",
       "      <td>6709.528824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11060.000000</td>\n",
       "      <td>677.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23878.000000</td>\n",
       "      <td>1637.000000</td>\n",
       "      <td>205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37628.000000</td>\n",
       "      <td>5238.000000</td>\n",
       "      <td>796.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>68400.000000</td>\n",
       "      <td>8522.000000</td>\n",
       "      <td>501498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id        item_id       playtime\n",
       "count  448211.000000  448211.000000  448211.000000\n",
       "mean    25832.526716    2992.618144    1539.262254\n",
       "std     17466.683483    2879.200191    6709.528824\n",
       "min         4.000000       0.000000       1.000000\n",
       "25%     11060.000000     677.000000      45.000000\n",
       "50%     23878.000000    1637.000000     205.000000\n",
       "75%     37628.000000    5238.000000     796.000000\n",
       "max     68400.000000    8522.000000  501498.000000"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_interactions_in.describe()\n",
    "#it describes the relation beetween the users and the games they played "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e36464",
   "metadata": {},
   "source": [
    "Context of the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee5a073",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb214b65",
   "metadata": {},
   "source": [
    "## interaction.csv processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e8276f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filtered = train_interactions.drop_duplicates([\"user_id\", \"item_id\"])\n",
    "\n",
    "# User with >=5 interactions\n",
    "train_filtered = train_filtered.groupby(\"user_id\").filter(lambda x: len(x) >= 5)\n",
    "\n",
    "# Items with >=2 interactions\n",
    "item_freq = train_filtered.groupby(\"item_id\").size()\n",
    "valid_items = item_freq[item_freq >= 2].index\n",
    "train_filtered = train_filtered[train_filtered[\"item_id\"].isin(valid_items)]\n",
    "\n",
    "\n",
    "train_filtered[\"split\"] = \"train\"\n",
    "test_interactions_in[\"split\"] = \"test\"\n",
    "\n",
    "all_interactions = pd.concat([train_filtered, test_interactions_in], ignore_index=True)\n",
    "\n",
    "\n",
    "all_interactions = all_interactions.rename(\n",
    "    columns={\n",
    "        \"user_id\": \"old_user_id\",\n",
    "        \"item_id\": \"old_item_id\"\n",
    "    }\n",
    ")\n",
    "# --- USERS ---\n",
    "user_id_mapping = {old_id: new_id for new_id, old_id in enumerate(all_interactions['old_user_id'].unique())}\n",
    "all_interactions['user_id'] = all_interactions['old_user_id'].map(user_id_mapping)\n",
    "new_to_old_user_id_mapping = {v: k for k, v in user_id_mapping.items()}\n",
    "\n",
    "# --- ITEMS ---\n",
    "item_id_mapping = {old_id: new_id for new_id, old_id in enumerate(all_interactions['old_item_id'].unique())}\n",
    "all_interactions['item_id'] = all_interactions['old_item_id'].map(item_id_mapping)\n",
    "new_to_old_item_id_mapping = {v: k for k, v in item_id_mapping.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fc909ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mapped  = all_interactions[all_interactions[\"split\"] == \"test\"].copy()\n",
    "train_mapped = all_interactions[all_interactions[\"split\"] == \"train\"].copy()\n",
    "\n",
    "item_freq = train_mapped.groupby(\"item_id\").size()\n",
    "valid_items = set(item_freq[item_freq >= 2].index)\n",
    "\n",
    "train_mapped = train_mapped[train_mapped[\"item_id\"].isin(valid_items)]\n",
    "test_mapped = test_mapped[test_mapped[\"item_id\"].isin(valid_items)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1bc49dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46713\n"
     ]
    }
   ],
   "source": [
    "num_users = train_mapped[\"user_id\"].nunique()\n",
    "print(num_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09d943c",
   "metadata": {},
   "source": [
    "## Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c6d4956e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Components.item_knn' from 'c:\\\\Users\\\\matte\\\\Desktop\\\\AIProject\\\\Components\\\\item_knn.py'>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Components.item_knn as gr\n",
    "importlib.reload(gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe04ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matte\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\_index.py:151: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from Components.my_cosine_similarity import my_cosine_similarity\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "import torch\n",
    "from Components.item_knn import item_knn_scores, scores2recommendations, save_user_item\n",
    "\n",
    "num_users = all_interactions[\"user_id\"].nunique()\n",
    "num_items = len(valid_items)\n",
    "\n",
    "X_train_binary = sp.csr_matrix(\n",
    "    (np.ones(len(train_mapped)),\n",
    "     (train_mapped[\"user_id\"].values, train_mapped[\"item_id\"].values)),\n",
    "    shape=(num_users, num_items)\n",
    ")\n",
    "\n",
    "\n",
    "X_test_in_binary = sp.csr_matrix(\n",
    "    (np.ones(len(test_mapped)),\n",
    "     (test_mapped[\"user_id\"].values, test_mapped[\"item_id\"].values)),\n",
    "    shape=(num_users, num_items)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# scores = item_knn_scores(X_train_binary, X_test_in_binary, 50)\n",
    "# df_recos = scores2recommendations(scores, X_test_in_binary, 20)\n",
    "# df_recos[\"user_id\"] = df_recos[\"user_id\"].map(new_to_old_user_id_mapping)\n",
    "# df_recos[\"item_id\"] = df_recos[\"item_id\"].map(new_to_old_item_id_mapping)\n",
    "\n",
    "#save_user_item(df_recos, \"submission_itemknn.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f864dafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Components.generate_recommendations' from 'c:\\\\Users\\\\matte\\\\Desktop\\\\AIProject\\\\Components\\\\generate_recommendations.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Components.generate_recommendations as gr\n",
    "importlib.reload(gr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6f941e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Loss: 190.7376 - Beta: 0.0001\n",
      "Epoch 2/30 - Loss: 155.9342 - Beta: 0.0002\n",
      "Epoch 3/30 - Loss: 154.8302 - Beta: 0.0004\n",
      "Epoch 4/30 - Loss: 154.6940 - Beta: 0.0005\n",
      "Epoch 5/30 - Loss: 154.5784 - Beta: 0.0006\n",
      "Epoch 6/30 - Loss: 154.3436 - Beta: 0.0007\n",
      "Epoch 7/30 - Loss: 154.0062 - Beta: 0.0008\n",
      "Epoch 8/30 - Loss: 153.9642 - Beta: 0.0010\n",
      "Epoch 9/30 - Loss: 153.7860 - Beta: 0.0011\n",
      "Epoch 10/30 - Loss: 153.6013 - Beta: 0.0012\n",
      "Epoch 11/30 - Loss: 153.0719 - Beta: 0.0013\n",
      "Epoch 12/30 - Loss: 151.9877 - Beta: 0.0014\n",
      "Epoch 13/30 - Loss: 151.1547 - Beta: 0.0016\n",
      "Epoch 14/30 - Loss: 150.7140 - Beta: 0.0017\n",
      "Epoch 15/30 - Loss: 150.5086 - Beta: 0.0018\n",
      "Epoch 16/30 - Loss: 150.4418 - Beta: 0.0019\n",
      "Epoch 17/30 - Loss: 150.3630 - Beta: 0.0020\n",
      "Epoch 18/30 - Loss: 150.3190 - Beta: 0.0022\n",
      "Epoch 19/30 - Loss: 150.2542 - Beta: 0.0023\n",
      "Epoch 20/30 - Loss: 150.1953 - Beta: 0.0024\n",
      "Epoch 21/30 - Loss: 150.0869 - Beta: 0.0025\n",
      "Epoch 22/30 - Loss: 149.9371 - Beta: 0.0026\n",
      "Epoch 23/30 - Loss: 149.6850 - Beta: 0.0028\n",
      "Epoch 24/30 - Loss: 149.3146 - Beta: 0.0029\n",
      "Epoch 25/30 - Loss: 148.9297 - Beta: 0.0030\n",
      "Epoch 26/30 - Loss: 148.6618 - Beta: 0.0031\n",
      "Epoch 27/30 - Loss: 148.4841 - Beta: 0.0032\n",
      "Epoch 28/30 - Loss: 148.3368 - Beta: 0.0034\n",
      "Epoch 29/30 - Loss: 148.2524 - Beta: 0.0035\n",
      "Epoch 30/30 - Loss: 148.2625 - Beta: 0.0036\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from Components.multiVAE import MultiVAE\n",
    "\n",
    "# ============================================================\n",
    "# INITIALIZE MODEL\n",
    "# ============================================================\n",
    "n_items = X_train_binary.shape[1]\n",
    "train_user_ids = train_mapped[\"user_id\"].unique()\n",
    "n_users_train = len(train_user_ids)\n",
    "X_train_dense = torch.FloatTensor(X_train_binary.toarray())\n",
    "\n",
    "row_sums = X_train_dense.sum(1, keepdim=True)\n",
    "X_train_dense = X_train_dense / torch.clamp(row_sums, min=1.0)\n",
    "\n",
    "p_dims = [600, 200, n_items]\n",
    "model = MultiVAE(p_dims, dropout=0.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ============================================================\n",
    "# TRAINING LOOP\n",
    "# ============================================================\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 2000\n",
    "\n",
    "total_anneal_steps = 200000   # recommended by the paper\n",
    "anneal_cap = 1.0              # max value for beta\n",
    "update_count = 0              # global step counter\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    perm = torch.randperm(n_users_train)\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for start in range(0, n_users_train, batch_size):\n",
    "        end = start + batch_size\n",
    "        batch_idx = perm[start:end]\n",
    "        batch = X_train_dense[batch_idx]\n",
    "\n",
    "        # ===== KL annealing =====\n",
    "        if total_anneal_steps > 0:\n",
    "            beta = min(anneal_cap, update_count / total_anneal_steps)\n",
    "        else:\n",
    "            beta = anneal_cap\n",
    "\n",
    "        logits, mu, logvar = model(batch)\n",
    "        loss, _, _ = model.loss_function(logits, batch, mu, logvar, beta)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        update_count += 1\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "987fdd43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Components.generate_recommendations' from 'c:\\\\Users\\\\matte\\\\Desktop\\\\AIProject\\\\Components\\\\generate_recommendations.py'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Components.generate_recommendations as gr\n",
    "importlib.reload(gr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b28291d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13579\n"
     ]
    }
   ],
   "source": [
    "test_users = np.sort(test_mapped[\"user_id\"].unique())\n",
    "print(len(test_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cf8aeafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Components.generate_recommendations import multivae_recommend, save_submission\n",
    "\n",
    "\n",
    "\n",
    "test_users = np.sort(test_mapped[\"user_id\"].unique())\n",
    "n_test_users = len(test_users)\n",
    "\n",
    "user_to_row = {u: i for i, u in enumerate(test_users)}\n",
    "index_to_user = {i: u for i, u in enumerate(test_users)}\n",
    "\n",
    "rows = test_mapped[\"user_id\"].map(user_to_row).values\n",
    "cols = test_mapped[\"item_id\"].values\n",
    "data = np.ones(len(test_mapped))\n",
    "\n",
    "X_test_in_binaryMV = sp.csr_matrix(\n",
    "    (data, (rows, cols)),\n",
    "    shape=(n_test_users, num_items)\n",
    ")\n",
    "\n",
    "X_dense_test_in = torch.FloatTensor(X_test_in_binaryMV.toarray())\n",
    "\n",
    "row_sums_test = X_dense_test_in.sum(1, keepdim=True)\n",
    "X_dense_test_in = X_dense_test_in / torch.clamp(row_sums_test, min=1.0)\n",
    "\n",
    "known_items = {}\n",
    "\n",
    "# known_items \n",
    "for row in train_mapped.itertuples():\n",
    "    u = row.user_id\n",
    "    if u in user_to_row:   \n",
    "        known_items[user_to_row[u]] = known_items.get(user_to_row[u], set())\n",
    "        known_items[user_to_row[u]].add(row.item_id)\n",
    "\n",
    "# known_items\n",
    "for row in test_mapped.itertuples():\n",
    "    u = row.user_id\n",
    "    known_items[user_to_row[u]] = known_items.get(user_to_row[u], set())\n",
    "    known_items[user_to_row[u]].add(row.item_id)\n",
    "\n",
    "# convert to lists\n",
    "known_items = {k: list(v) for k, v in known_items.items()}\n",
    "\n",
    "rec_df = multivae_recommend(\n",
    "    model=model,\n",
    "    X_dense_test_in=X_dense_test_in,\n",
    "    index_to_user=index_to_user,\n",
    "    known_items=known_items,\n",
    "    top_k=20\n",
    ")\n",
    "\n",
    "\n",
    "rec_df[\"user_id\"] = rec_df[\"user_id\"].map(new_to_old_user_id_mapping)\n",
    "\n",
    "# item_id: mapped → old\n",
    "rec_df[\"item_id\"] = rec_df[\"item_id\"].map(new_to_old_item_id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "87974d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to submission_multivae.csv\n",
      "MultiVAE recommendations saved to submission_multivae.csv\n"
     ]
    }
   ],
   "source": [
    "save_submission(rec_df, \"submission_multivae.csv\")\n",
    "print(\"MultiVAE recommendations saved to submission_multivae.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
