{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d04fd2c",
   "metadata": {},
   "source": [
    "# Evaluating the accuracy of two different racomandation strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368ad989",
   "metadata": {},
   "source": [
    "The main objective of this project is to develop, implement, and evaluate multiple recommendation models using state-of-the-art techniques in collaborative filtering. In particular, the work focuses on comparing traditional methods—such as item-kNN and matrix factorization—with more advanced neural approache that is MultiVAE. The aim is to understand how different modeling choices, data preprocessing strategies, and evaluation metrics impact recommendation quality, and to identify the methods that achieve the best performance on the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb3115f",
   "metadata": {},
   "source": [
    "Importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7eaafba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3052625e",
   "metadata": {},
   "source": [
    "## DATASET\n",
    "\n",
    "From the Steam dataset, I am using the following components:\n",
    "- train_interactions.csv & test_interactions_in.csv\n",
    "    - user_id\n",
    "    - item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad176413",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_foldername = \"~/OneDrive - Università degli Studi di Milano-Bicocca/Magistrale/AI/cleaned_datasets_students\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38c39b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interactions = pd.read_csv(f\"{dataset_foldername}/train_interactions.csv\")\n",
    "games = pd.read_csv(f\"{dataset_foldername}/games.csv\")\n",
    "test_interactions_in = pd.read_csv(f\"{dataset_foldername}/test_interactions_in.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb214b65",
   "metadata": {},
   "source": [
    "## Interaction.csv pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8276f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filtered = train_interactions.drop_duplicates([\"user_id\", \"item_id\"])\n",
    "\n",
    "# User with >=5 interactions\n",
    "train_filtered = train_filtered.groupby(\"user_id\").filter(lambda x: len(x) >= 5)\n",
    "\n",
    "# Items with >=2 interactions\n",
    "item_freq = train_filtered.groupby(\"item_id\").size()\n",
    "valid_items = item_freq[item_freq >= 2].index\n",
    "train_filtered = train_filtered[train_filtered[\"item_id\"].isin(valid_items)]\n",
    "\n",
    "\n",
    "train_filtered[\"split\"] = \"train\"\n",
    "test_interactions_in[\"split\"] = \"test\"\n",
    "\n",
    "all_interactions = pd.concat([train_filtered, test_interactions_in], ignore_index=True)\n",
    "\n",
    "\n",
    "all_interactions = all_interactions.rename(\n",
    "    columns={\n",
    "        \"user_id\": \"old_user_id\",\n",
    "        \"item_id\": \"old_item_id\"\n",
    "    }\n",
    ")\n",
    "# --- USERS ---\n",
    "user_id_mapping = {old_id: new_id for new_id, old_id in enumerate(all_interactions['old_user_id'].unique())}\n",
    "all_interactions['user_id'] = all_interactions['old_user_id'].map(user_id_mapping)\n",
    "new_to_old_user_id_mapping = {v: k for k, v in user_id_mapping.items()}\n",
    "\n",
    "# --- ITEMS ---\n",
    "item_id_mapping = {old_id: new_id for new_id, old_id in enumerate(all_interactions['old_item_id'].unique())}\n",
    "all_interactions['item_id'] = all_interactions['old_item_id'].map(item_id_mapping)\n",
    "new_to_old_item_id_mapping = {v: k for k, v in item_id_mapping.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc909ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mapped  = all_interactions[all_interactions[\"split\"] == \"test\"].copy()\n",
    "train_mapped = all_interactions[all_interactions[\"split\"] == \"train\"].copy()\n",
    "\n",
    "item_freq = train_mapped.groupby(\"item_id\").size()\n",
    "valid_items = set(item_freq[item_freq >= 2].index)\n",
    "\n",
    "train_mapped = train_mapped[train_mapped[\"item_id\"].isin(valid_items)]\n",
    "test_mapped = test_mapped[test_mapped[\"item_id\"].isin(valid_items)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2e6dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "num_users = all_interactions[\"user_id\"].nunique()\n",
    "num_items = len(valid_items)\n",
    "\n",
    "X_train_binary = sp.csr_matrix(\n",
    "    (np.ones(len(train_mapped)),\n",
    "     (train_mapped[\"user_id\"].values, train_mapped[\"item_id\"].values)),\n",
    "    shape=(num_users, num_items)\n",
    ")\n",
    "\n",
    "\n",
    "X_test_in_binary = sp.csr_matrix(\n",
    "    (np.ones(len(test_mapped)),\n",
    "     (test_mapped[\"user_id\"].values, test_mapped[\"item_id\"].values)),\n",
    "    shape=(num_users, num_items)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09d943c",
   "metadata": {},
   "source": [
    "## Recommendation\n",
    "\n",
    "### ITEM-KNN\n",
    "Item-kNN is a neighborhood-based collaborative filtering method that recommends items by measuring similarity between products. The underlying idea is that items consumed by similar groups of users are likely to be related. To generate recommendations, item-kNN computes item–item similarity scores—commonly using cosine similarity—based on user interaction patterns. For a given user, the model identifies items similar to those they have already interacted with and ranks them according to aggregated similarity.\n",
    "\n",
    "### MultiVAE\n",
    "MultiVAE (Multinomial Variational Autoencoder) is a deep generative model designed for collaborative filtering, leveraging the power of variational inference to learn meaningful latent representations of users. Unlike traditional methods, MultiVAE models the user–item interaction vector as a multinomial distribution and uses an encoder–decoder architecture to reconstruct user preferences while regularizing the latent space through a KL divergence term. The encoder maps each user’s interaction history to a continuous latent vector, while the decoder predicts the probability distribution over all items. This allows MultiVAE to capture complex, nonlinear patterns in the data and produce highly personalized recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f404c743",
   "metadata": {},
   "source": [
    "#### ITEM-KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbe04ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matte\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\_index.py:151: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-item recommendation file saved to submission_itemknn.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from Components.my_cosine_similarity import my_cosine_similarity\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "import torch\n",
    "from Components.item_knn import item_knn_scores, scores2recommendations, save_user_item\n",
    "\n",
    "scores = item_knn_scores(X_train_binary, X_test_in_binary, 50)\n",
    "df_recos = scores2recommendations(scores, X_test_in_binary, 20)\n",
    "df_recos[\"user_id\"] = df_recos[\"user_id\"].map(new_to_old_user_id_mapping)\n",
    "df_recos[\"item_id\"] = df_recos[\"item_id\"].map(new_to_old_item_id_mapping)\n",
    "\n",
    "save_user_item(df_recos, \"submission_itemknn.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f864dafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Components.generate_recommendations' from 'c:\\\\Users\\\\matte\\\\Desktop\\\\AIProject\\\\Components\\\\generate_recommendations.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Components.generate_recommendations as gr\n",
    "importlib.reload(gr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe642318",
   "metadata": {},
   "source": [
    "#### MultiVAE-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae6f941e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Loss: 9184.0706\n",
      "Epoch 2/30 - Loss: 8090.0362\n",
      "Epoch 3/30 - Loss: 8100.1107\n",
      "Epoch 4/30 - Loss: 8053.6545\n",
      "Epoch 5/30 - Loss: 8052.5176\n",
      "Epoch 6/30 - Loss: 8060.7126\n",
      "Epoch 7/30 - Loss: 8020.0146\n",
      "Epoch 8/30 - Loss: 7963.2427\n",
      "Epoch 9/30 - Loss: 7941.4982\n",
      "Epoch 10/30 - Loss: 7919.0898\n",
      "Epoch 11/30 - Loss: 7908.7787\n",
      "Epoch 12/30 - Loss: 7882.6528\n",
      "Epoch 13/30 - Loss: 7882.7292\n",
      "Epoch 14/30 - Loss: 7842.0348\n",
      "Epoch 15/30 - Loss: 7794.2228\n",
      "Epoch 16/30 - Loss: 7795.9257\n",
      "Epoch 17/30 - Loss: 7798.6572\n",
      "Epoch 18/30 - Loss: 7793.8939\n",
      "Epoch 19/30 - Loss: 7773.3136\n",
      "Epoch 20/30 - Loss: 7784.3473\n",
      "Epoch 21/30 - Loss: 7777.4090\n",
      "Epoch 22/30 - Loss: 7799.2559\n",
      "Epoch 23/30 - Loss: 7776.3572\n",
      "Epoch 24/30 - Loss: 7721.0755\n",
      "Epoch 25/30 - Loss: 7698.5770\n",
      "Epoch 26/30 - Loss: 7686.6870\n",
      "Epoch 27/30 - Loss: 7701.5273\n",
      "Epoch 28/30 - Loss: 7665.9412\n",
      "Epoch 29/30 - Loss: 7671.2166\n",
      "Epoch 30/30 - Loss: 7661.5078\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from Components.multiVAE import MultiVAE\n",
    "\n",
    "# ============================================================\n",
    "# INITIALIZE MODEL\n",
    "# ============================================================\n",
    "n_items = X_train_binary.shape[1]\n",
    "train_user_ids = train_mapped[\"user_id\"].unique()\n",
    "n_users_train = len(train_user_ids)\n",
    "X_train_dense = torch.FloatTensor(X_train_binary.toarray())\n",
    "\n",
    "# row_sums = X_train_dense.sum(1, keepdim=True)\n",
    "# X_train_dense = X_train_dense / torch.clamp(row_sums, min=1.0)\n",
    "\n",
    "p_dims = [600, 200, n_items]\n",
    "model = MultiVAE(p_dims, dropout=0.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ============================================================\n",
    "# TRAINING LOOP\n",
    "# ============================================================\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 2000\n",
    "\n",
    "total_anneal_steps = 200000   # recommended by the paper\n",
    "anneal_cap = 1.0              # max value for beta\n",
    "update_count = 0              # global step counter\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    perm = torch.randperm(n_users_train)\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for start in range(0, n_users_train, batch_size):\n",
    "        end = start + batch_size\n",
    "        batch_idx = perm[start:end]\n",
    "        batch = X_train_dense[batch_idx]\n",
    "\n",
    "        # ===== KL annealing =====\n",
    "        if total_anneal_steps > 0:\n",
    "            beta = min(anneal_cap, update_count / total_anneal_steps)\n",
    "        else:\n",
    "            beta = anneal_cap\n",
    "\n",
    "        logits, mu, logvar = model(batch)\n",
    "        loss, _, _ = model.loss_function(logits, batch, mu, logvar, beta)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        update_count += 1\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "987fdd43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Components.generate_recommendations' from 'c:\\\\Users\\\\matte\\\\Desktop\\\\AIProject\\\\Components\\\\generate_recommendations.py'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Components.generate_recommendations as gr\n",
    "importlib.reload(gr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1aaaf5",
   "metadata": {},
   "source": [
    "### Multivae-recommandation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf8aeafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Components.generate_recommendations import multivae_recommend, save_submission\n",
    "\n",
    "test_users = np.sort(test_mapped[\"user_id\"].unique())\n",
    "n_test_users = len(test_users)\n",
    "\n",
    "user_to_row = {u: i for i, u in enumerate(test_users)}\n",
    "index_to_user = {i: u for i, u in enumerate(test_users)}\n",
    "\n",
    "rows = test_mapped[\"user_id\"].map(user_to_row).values\n",
    "cols = test_mapped[\"item_id\"].values\n",
    "data = np.ones(len(test_mapped))\n",
    "\n",
    "X_test_in_binaryMV = sp.csr_matrix(\n",
    "    (data, (rows, cols)),\n",
    "    shape=(n_test_users, num_items)\n",
    ")\n",
    "\n",
    "X_dense_test_in = torch.FloatTensor(X_test_in_binaryMV.toarray())\n",
    "\n",
    "row_sums_test = X_dense_test_in.sum(1, keepdim=True)\n",
    "X_dense_test_in = X_dense_test_in / torch.clamp(row_sums_test, min=1.0)\n",
    "\n",
    "known_items = {}\n",
    "\n",
    "# known_items \n",
    "for row in train_mapped.itertuples():\n",
    "    u = row.user_id\n",
    "    if u in user_to_row:   \n",
    "        known_items[user_to_row[u]] = known_items.get(user_to_row[u], set())\n",
    "        known_items[user_to_row[u]].add(row.item_id)\n",
    "\n",
    "# known_items\n",
    "for row in test_mapped.itertuples():\n",
    "    u = row.user_id\n",
    "    known_items[user_to_row[u]] = known_items.get(user_to_row[u], set())\n",
    "    known_items[user_to_row[u]].add(row.item_id)\n",
    "\n",
    "# convert to lists\n",
    "known_items = {k: list(v) for k, v in known_items.items()}\n",
    "\n",
    "rec_df = multivae_recommend(\n",
    "    model=model,\n",
    "    X_dense_test_in=X_dense_test_in,\n",
    "    index_to_user=index_to_user,\n",
    "    known_items=known_items,\n",
    "    top_k=20\n",
    ")\n",
    "\n",
    "\n",
    "rec_df[\"user_id\"] = rec_df[\"user_id\"].map(new_to_old_user_id_mapping)\n",
    "\n",
    "# item_id: mapped → old\n",
    "rec_df[\"item_id\"] = rec_df[\"item_id\"].map(new_to_old_item_id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87974d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to submission_multivae.csv\n",
      "MultiVAE recommendations saved to submission_multivae.csv\n"
     ]
    }
   ],
   "source": [
    "save_submission(rec_df, \"submission_multivae.csv\")\n",
    "print(\"MultiVAE recommendations saved to submission_multivae.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
